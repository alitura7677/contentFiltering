In the mathematical discipline of linear algebra , the Schur decomposition or Schur triangulation , named after Issai Schur , is a matrix decomposition . # Statement # The Schur decomposition reads as follows : if ' ' A ' ' is a ' ' n ' ' &amp;times ; ' ' n ' ' square matrix with complex entries , then ' ' A ' ' can be expressed as :  A = Q U Q-1  where ' ' Q ' ' is a unitary matrix ( so that its inverse ' ' Q ' '  1  is also the conjugate transpose ' ' Q ' ' * of ' ' Q ' ' ) , and ' ' U ' ' is an upper triangular matrix , which is called a Schur form of ' ' A ' ' . Since ' ' U ' ' is similar to ' ' A ' ' , it has the same multiset of eigenvalues , and since it is triangular , those eigenvalues are the diagonal entries of ' ' U ' ' . @ @ @ @ @ @ @ @ @ @ of ' ' A ' ' -invariant subspaces 0 = ' ' V ' '  0  ' ' V ' '  1  .. ' ' V  n  ' ' = C  ' ' n ' '  , and that there exists an ordered orthonormal basis ( for the standard Hermitian form of C  ' ' n ' '  ) such that the first ' ' i ' ' basis vectors span ' ' V ' '  ' ' i ' '  for each ' ' i ' ' occurring in the nested sequence . Phrased somewhat differently , the first part says that a linear operator ' ' J ' ' on a complex finite-dimensional vector space stabilizes a complete flag ( ' ' V ' '  1  , ... , ' ' V  n  ' ' ) . # Proof # A constructive proof for the Schur decomposition is as follows : every operator ' ' A ' ' on a complex finite-dimensional vector space has an eigenvalue ' ' &amp;lambda ; ' ' @ @ @ @ @ @ @ @ @ @ ;  ' ' . Let ' ' V  &amp;lambda ;  ' '   be its orthogonal complement . It is clear that , with respect to this orthogonal decomposition , ' ' A ' ' has matrix representation ( one can pick here any orthonormal bases ' ' Z  1  ' ' and ' ' Z  2  ' ' spanning ' ' V  &amp;lambda ;  ' ' and ' ' V  &amp;lambda ;  ' '   respectively ) :  beginbmatrix Z1 &amp; Z2 endbmatrix* A beginbmatrixZ1 &amp; Z2endbmatrix = beginbmatrix lambda , Ilambda &amp; A12 0 &amp; A22 endbmatrix : beginmatrix Vlambda oplus Vlambdaperp endmatrix rightarrow beginmatrix Vlambda oplus Vlambdaperp endmatrix  where ' ' I  &amp;lambda ;  ' ' is the identity operator on ' ' V  &amp;lambda ;  ' ' . The above matrix would be upper-triangular except for the ' ' A ' '  22  block . But exactly the same procedure can be applied to the sub-matrix ' ' A ' '  22  , viewed @ @ @ @ @ @ @ @ @ @  ' '   , and its submatrices . Continue this way n times . Thus the space C  ' ' n ' '  will be exhausted and the procedure has yielded the desired result . The above argument can be slightly restated as follows : let ' ' &amp;lambda ; ' ' be an eigenvalue of ' ' A ' ' , corresponding to some eigenspace ' ' V  &amp;lambda ;  ' ' . ' ' A ' ' induces an operator ' ' T ' ' on the quotient space C  ' ' n ' '  modulo ' ' V  &amp;lambda ;  ' ' . This operator is precisely the ' ' A ' '  22  submatrix from above . As before , ' ' T ' ' would have an eigenspace , say ' ' W  &amp;mu ;  ' ' C  ' ' n ' '  modulo ' ' V  &amp;lambda ;  ' ' . Notice the preimage of ' ' W  &amp;mu ;  ' ' under the quotient @ @ @ @ @ @ @ @ @ @ ' that contains ' ' V  &amp;lambda ;  ' ' . Continue this way until the resulting quotient space has dimension 0 . Then the successive preimages of the eigenspaces found at each step form a flag that ' ' A ' ' stabilizes. # Notes # Although every square matrix has a Schur decomposition , in general this decomposition is not unique . For example , the eigenspace ' ' V  &amp;lambda ;  ' ' can have dimension 1 , in which case any orthonormal basis for ' ' V  &amp;lambda ;  ' ' would lead to the desired result . Write the triangular matrix ' ' U ' ' as ' ' U ' ' = ' ' D ' ' + ' ' N ' ' , where ' ' D ' ' is diagonal and ' ' N ' ' is strictly upper triangular ( and thus a nilpotent matrix ) . The diagonal matrix ' ' D ' ' contains the eigenvalues of ' ' A ' ' in arbitrary order ( hence its Frobenius norm , squared , is @ @ @ @ @ @ @ @ @ @ ' ' A ' ' , while the Frobenius norm of ' ' A ' ' , squared , is the sum of the squared singular values of ' ' A ' ' ) . The nilpotent part ' ' N ' ' is generally not unique either , but its Frobenius norm is uniquely determined by ' ' A ' ' ( just because the Frobenius norm of A is equal to the Frobenius norm of ' ' U ' ' = ' ' D ' ' + ' ' N ' ' ) . It is clear that if ' ' A ' ' is a normal matrix , then ' ' U ' ' from its Schur decomposition must be a diagonal matrix and the column vectors of ' ' Q ' ' are the eigenvectors of ' ' A ' ' . Therefore , the Schur decomposition extends the spectral decomposition . In particular , if ' ' A ' ' is positive definite , the Schur decomposition of ' ' A ' ' , its spectral decomposition , and its singular value decomposition coincide . A @ @ @ @ @ @ @ @ @ @ of matrices can be simultaneously triangularized , i.e. there exists a unitary matrix ' ' Q ' ' such that , for every ' ' A  i  ' ' in the given family , ' ' Q A  i  Q* ' ' is upper triangular . This can be readily deduced from the above proof . Take element ' ' A ' ' from ' ' A  i  ' ' and again consider an eigenspace ' ' V  A  ' ' . Then ' ' V  A  ' ' is invariant under all matrices in ' ' A  i  ' ' . Therefore all matrices in ' ' A  i  ' ' must share one common eigenvector in ' ' V  A  ' ' . Induction then proves the claim . As a corollary , we have that every commuting family of normal matrices can be simultaneously diagonalized . In the infinite dimensional setting , not every bounded operator on a Banach space has an invariant subspace . However , the upper-triangularization of an arbitrary @ @ @ @ @ @ @ @ @ @ operator on a complex Banach space has a nest of closed invariant subspaces. # Computation # Schur decomposition of a given matrix is known to be numerically computed by QR algorithm or its variants . In other words , the roots of the characteristic polynomial corresponding to the matrix are not necessarily computed ahead in order to obtain its Schur decomposition . Conversely , QR algorithm can be used to compute the roots of any given characteristic polynomial by finding the Schur decomposition of its companion matrix . Similarly , QR algorithm is used to compute the eigenvalues of any given matrix , which are the diagonal entries of the upper triangular matrix of the Schur decomposition . See the Nonsymmetric Eigenproblems section in LAPACK Users ' Guide . # Applications # Lie theory applications include : * Every invertible operator is contained in a Borel group . * Every operator fixes a point of the flag manifold . # Generalized Schur decomposition # Given square matrices ' ' A ' ' and ' ' B ' ' , the generalized Schur decomposition factorizes both matrices as  A=QSZ*  and @ @ @ @ @ @ @ @ @ @ and ' ' Z ' ' are unitary , and ' ' S ' ' and ' ' T ' ' are upper triangular . The generalized Schur decomposition is also sometimes called the QZ decomposition . The generalized eigenvalues  lambda  that solve the generalized eigenvalue problem  Ax=lambda Bx  ( where ' ' x ' ' is an unknown nonzero vector ) can be calculated as the ratio of the diagonal elements of ' ' S ' ' to those of ' ' T ' ' . That is , using subscripts to denote matrix elements , the ' ' i ' ' th generalized eigenvalue  lambdai  satisfies  lambdai=Sii/Tii  . # References # **14;362474;references 